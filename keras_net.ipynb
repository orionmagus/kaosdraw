{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.numbers import rarray, ResultsArray,pool\n",
    "import tensorflow as tf\n",
    "from numbers import Number\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.backend as bt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.e ** -x)\n",
    "\n",
    "\n",
    "def sigmoid_deriv(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "\n",
    "def binarr2int(arr):\n",
    "    return int(''.join(np.array(arr).astype(str)), 2)\n",
    "\n",
    "\n",
    "def binmax(arr):\n",
    "    return np.array([1 if n > 0 else 0 for n in arr])\n",
    "\n",
    "\n",
    "class ResultInt(object):\n",
    "    def __init__(self, value=(1,)):\n",
    "        self._N = pool(52)\n",
    "        if not isinstance(value, list) or not isinstance(value, tuple):\n",
    "            if isinstance(value, Number):\n",
    "                if value <= 52:\n",
    "                    value = [value]\n",
    "                else:\n",
    "                    value = binarr_to_values(\n",
    "                        np.array(list(bin(round(value))[2:])).astype(int))\n",
    "            if isinstance(value, np.ndarray):\n",
    "                if np.max(value) == 1:\n",
    "                    value = binarr_to_values(value)\n",
    "                else:\n",
    "                    value = value.tolist()\n",
    "            if isinstance(value, str):\n",
    "                if len(value) > 3:\n",
    "                    value = binarr_to_values(\n",
    "                        np.array(list(value)).astype(int))\n",
    "        else:\n",
    "            if len(value) > 12:\n",
    "                value = binarr_to_values(\n",
    "                    np.array(list(value)).astype(int))\n",
    "\n",
    "        self._i = list(map(lambda x: x % 52 if x != 52 else 52, value))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}(N={len(self._N)}, value={self._i})\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return bin(int(self))[2:]\n",
    "    @property\n",
    "    def arr(self):\n",
    "        return np.where(np.isin(self._N, self._i), 1, 0)\n",
    "\n",
    "    def __int__(self):\n",
    "        return int(''.join(np.array(self.arr).astype(str)), 2)\n",
    "\n",
    "    def __index__(self):\n",
    "        return int(self)\n",
    "\n",
    "    def __or__(self, other):\n",
    "        other = other if isinstance(\n",
    "            other, self.__class__) else self.__class__(other)\n",
    "        return self.__class__(int(self) | int(other))\n",
    "\n",
    "    def __and__(self, other):\n",
    "        other = other if isinstance(\n",
    "            other, self.__class__) else self.__class__(other)\n",
    "        return self.__class__(int(self) & int(other))\n",
    "\n",
    "    def __not__(self):\n",
    "        return self.__class__(~int(self))\n",
    "\n",
    "    def __xor__(self, other):\n",
    "        other = other if isinstance(\n",
    "            other, self.__class__) else self.__class__(other)\n",
    "        return self.__class__(int(self) ^ int(other))\n",
    "    # def __div__(self, other):\n",
    "    #     other = other if isinstance(\n",
    "    #         other, self.__class__) else self.__class__(other)\n",
    "    #     return np.sum(np.array(list(bin(int(self) & int(other))[2:])).astype(int)) / 6.0\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        other = other if isinstance(\n",
    "            other, self.__class__) else self.__class__(other)\n",
    "        t, p = (self._i, other._i)\n",
    "        return self.__class__([dgt for dgt in np.where(np.isin(t, p), 0, p).tolist() if dgt > 0])\n",
    "\n",
    "    def __add__(self, other):\n",
    "        other = other if isinstance(\n",
    "            other, self.__class__) else self.__class__(other)\n",
    "        return self.__class__(binmax(np.array(self.arr) + np.array(other.arr)))\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        other = other if isinstance(\n",
    "            other, self.__class__) else self.__class__(other)\n",
    "        return self.__class__(binmax(np.array(self.arr) * np.array(other.arr)))\n",
    "\n",
    "    # def __idiv__(self, other):\n",
    "    #     return self.__div__(other)\n",
    "\n",
    "    def __truediv__(self, other):\n",
    "        other = other if isinstance(\n",
    "            other, self.__class__) else self.__class__(other)\n",
    "        return np.sum(np.array(list(bin(int(self) & int(other))[2:])).astype(int)) / 6.0\n",
    "\n",
    "    def __itruediv__(self, other):\n",
    "        return self.__truediv__(other)\n",
    "\n",
    "    def __isub__(self, other):\n",
    "        return self.__sub__(other)\n",
    "\n",
    "    def __iadd__(self, other):\n",
    "        return self.__add__(other)\n",
    "\n",
    "    def __imul__(self, other):\n",
    "        return self.__mul__(other)\n",
    "\n",
    "def cols2rec(cols=('ball1', 'ball2', 'ball3', 'ball4', 'ball5', 'ball6', 'bonusBall')):\n",
    "    def _inner(x):\n",
    "        x['record'] = ResultInt([int(x[c]) for c in cols])\n",
    "        return x\n",
    "    return _inner\n",
    "\n",
    "def cols2nums(cols=('ball1', 'ball2', 'ball3', 'ball4', 'ball5', 'ball6', 'bonusBall')):\n",
    "    def _inner(x):\n",
    "        x['record'] = np.array([int(x[c]) for c in cols])\n",
    "        return x\n",
    "    return _inner\n",
    "\n",
    "def as_record(data, cols=('ball1', 'ball2', 'ball3', 'ball4', 'ball5', 'ball6')):\n",
    "    data['record'] = 0\n",
    "    fn = cols2rec(cols)\n",
    "    return data.apply(fn, axis=1)\n",
    "\n",
    "def train_split(data, split_by=25, cols=('ball1', 'ball2', 'ball3', 'ball4', 'ball5', 'ball6')):\n",
    "    r, c = data.shape\n",
    "    chunk_indices = [(k, min(r, k+split_by)-1, min(r, k+split_by))\n",
    "                     for k in range(0, r-split_by)]    \n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for s, e, t in chunk_indices:\n",
    "        inputs.append(data[s:e].record.tolist())\n",
    "        targets.append(data[t:t+1].record)\n",
    "    ncols = ['R{}'.format(x) for x in range(1, split_by)]\n",
    "    trgs = pd.concat(targets)\n",
    "    return pd.DataFrame(inputs, columns=ncols, index=trgs.index), trgs\n",
    "\n",
    "@tf.function\n",
    "def accuracy_met(y_true, y_pred):\n",
    "    #t, p = y_true.numpy(), y_pred.numpy()  \n",
    "    return tf.sets.size(tf.sets.intersection(y_true, y_pred)) * 1.0/tf.sets.size(y_pred)\n",
    "  \n",
    "def create_model(inputs=5, shape=([6, 'relu'], [24, 'relu'], [1,'sigmoid']), \n",
    "                loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']):\n",
    "    model = Sequential()\n",
    "    i = 0\n",
    "    #feature_columns = []\n",
    "    #     for f in ['ball1', 'ball2', 'ball3', 'ball4', 'ball5', 'ball6', ]:\n",
    "    #         feature_columns.append(feature_column.numeric_column(f, dtype=tf.int32))\n",
    "        \n",
    "    #feature_layer = layers.DenseFeatures(feature_columns)\n",
    "    #model.add(feature_layer)\n",
    "    for s, a in shape:\n",
    "        kw = {\n",
    "            'activation': a\n",
    "        }\n",
    "        if i == 0:\n",
    "           kw['input_dim'] = inputs \n",
    "        model.add(Dense(s, **kw))\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model\n",
    "\n",
    "def ttv_data(dataframe, s=0.2):\n",
    "    train, test = train_test_split(dataframe, test_size=s)\n",
    "    train, validate = train_test_split(train, test_size=s)\n",
    "    return train, test, validate\n",
    "\n",
    "def load_data(fname=\"data/lotto_daf.pickle\", \n",
    "              cols=('drawNumber', 'ball1', 'ball2', 'ball3', 'ball4', 'ball5', 'ball6', 'bonusBall')):\n",
    "    data = [[1994, '2020/02/08',3,41,37,28,51,42,14],[1995, '2020/02/12',16,18,32,38,39,44,31]]\n",
    "    kw = {\n",
    "        'columns': 'drawNumber,drawDate,ball1,ball2,ball3,ball4,ball5,ball6,bonusBall'.split(','),\n",
    "        'index': [n[0] for n in data]\n",
    "    }\n",
    "    df = pd.concat([pd.read_pickle(fname),pd.DataFrame(data, **kw)])\n",
    "    return df\n",
    "    for c in cols:\n",
    "        df[c] = df[c].astype(int)\n",
    "    return df[list(cols)]\n",
    "    \n",
    "# def facc():\n",
    "#     dense = tf.keras.layers.Dense(1, input_dim=6)    \n",
    "#     loss_fn = lambda: tf.reduce_sum((dense(x) - tf.constant([1., -1.])) ** 2.) \n",
    "#     kernel_fprop = [] \n",
    "#     with tf.autodiff.ForwardAccumulator( \n",
    "#         dense.kernel, tf.constant([0])) as acc: \n",
    "#     kernel_fprop.append(acc.jvp(loss_fn())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataset(dataframe, shuffle=False, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('record')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds\n",
    "\n",
    "def get_ttv():\n",
    "    data_orig = as_record(load_data())\n",
    "    cols=('drawNumber', 'ball1', 'ball2', 'ball3', 'ball4', 'ball5', 'ball6', 'bonusBall')\n",
    "    for c in cols:\n",
    "        data_orig[c] = data_orig[c].astype(int)\n",
    "    #.loc[df.dra\n",
    "    main_df = data_orig.copy()\n",
    "    dfr = main_df.pop('record')\n",
    "    dfr.index = dfr.index - 1\n",
    "    main_df = main_df.merge(dfr, how='left', left_index=True, right_index=True)\n",
    "    dd = main_df.pop('drawDate')\n",
    "    train, test, val = ttv_data(main_df)\n",
    "    return train, test, val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datint():\n",
    "    data_orig = load_data()\n",
    "    data = as_record(data_orig)\n",
    "    # data['record'] = data['record'].apply(lambda x: np.array(x))\n",
    "    inpts, trgs = train_split(data, split_by=6)\n",
    "    x = inpts.to_numpy()\n",
    "    y = trgs.to_numpy()\n",
    "    m = int(len(x)/ 2)\n",
    "    x, test_x = (x[:m], x[m:])\n",
    "    y, test_y = (y[:m], y[m:])\n",
    "    return [x, y, test_x, test_y]\n",
    "    \n",
    "x, y, test_x, test_y = datint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "model = create_model(inputs=5,optimizer=optimizer,metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_81 (Dense)             (None, 6)                 36        \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 24)                168       \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 229\n",
      "Trainable params: 229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[    274883837952,     141745455112,  141355967840276,\n",
       "            4449598702080,      10873745408],\n",
       "        [    141745455112,  141355967840276,    4449598702080,\n",
       "              10873745408,  167400779546632],\n",
       "        [ 141355967840276,    4449598702080,      10873745408,\n",
       "          167400779546632,    4707288350740],\n",
       "        ...,\n",
       "        [   8869107466818,      77319897156, 2256203229167618,\n",
       "            8813272925824, 1125899932271680],\n",
       "        [     77319897156, 2256203229167618,    8813272925824,\n",
       "         1125899932271680,     158997676033],\n",
       "        [2256203229167618,    8813272925824, 1125899932271680,\n",
       "             158997676033,  567350418079744]]),\n",
       " array([   4707288350740,    2270024564768,     274880037385,\n",
       "             68719476978,  141012940881936,       1627398150,\n",
       "           4569845209216,       3223453776,  356791527931904,\n",
       "           2216211726336,    4681648570404,     691500220544,\n",
       "            146297405568,  140806478432256,      19613089824,\n",
       "           4402349900802,        138412071,    1245540516105,\n",
       "           2268281177088,   35222087278592,     274882101420,\n",
       "           2199023648899,   18760421343552,   76965814992962,\n",
       "          70506183135316,     279173136643,   35201690378368,\n",
       "          35530251174144,  326005197635596,  150633361473538,\n",
       "          39583500730497,   17601313112067,    2269890480144,\n",
       "          70514775228544,     142271328256,     551232209936,\n",
       "         107753217490944,    9071516712961,     997774589952,\n",
       "                  557133,      68737835010,    8933531976856,\n",
       "           1237554569220,    2199291691432,   13202733670416,\n",
       "          70368782450952,    4995063742464,    4672924713104,\n",
       "           1385126961160,  180321249133568,        604061762,\n",
       "         281612418301968,     277562278401,   21440485130496,\n",
       "         158329947029510,   17901423689876,   13194274021632,\n",
       "         107890652217346,   79164845588868,   70643638993056,\n",
       "           4466765988871,    8796634120736,    4466800070784,\n",
       "             17251205392,  281477124849952,   71538049089537,\n",
       "         317213416357889,      70331203592,     549772894240,\n",
       "         140823396614208,    1099545199640,   83580063588354,\n",
       "            103687520256,  140892108242948,  159446634332416,\n",
       "            275450445832,  105624520114176,  143487341166864,\n",
       "         175921869423104,    1100656738305,     420908892688,\n",
       "           2474035413025,   70368745786368,       1694568448,\n",
       "            137439609922,       9668067392,          4263978,\n",
       "              5402394753,     274911469701,   19241587968000,\n",
       "             19341115392,   17627082915846,   10445360472704,\n",
       "         149679610269728,  281618858119176,    9896141529601,\n",
       "         149533581907976,  351843725606929,   73118605385728,\n",
       "           2199123985409,  158329758285833,        603982048,\n",
       "          70371197845536,  281492290813988,    2250563190848,\n",
       "          43980599869448,  105587492786432,     554063364108,\n",
       "                 3187716,     558346848256,   88237955613704,\n",
       "         140815871508552,  422246900305920,    1271318741008,\n",
       "          18142078435330,  285882552680448,   13194140058816,\n",
       "         141287244178561,   18778133889028,          8986888,\n",
       "           4398321270800,  180328505294848,     550024253762,\n",
       "                86508608,    4535552868353,    2199293805184,\n",
       "         294669124632864,  140874960863810,   87960938774656,\n",
       "                16813186,  175990720430080,      21475426944,\n",
       "          17593800884480,     345778421772,     550846414912,\n",
       "         141699561037825,  140773995716624,  281483573002368,\n",
       "          18966613327873,    2207948734481,  285875510444032,\n",
       "          72022306653184,    1236988592136,     241323475968,\n",
       "           4810363373088,    9363028836616,   35218756994176,\n",
       "           4400211300416,    2061584302097,  145135545352512,\n",
       "              2151678548,   35459318284290,     276224282625,\n",
       "          39591008552964,     274946589056,   71064530978816,\n",
       "            597268890624,       6983525376,  303740154281992,\n",
       "         422212474507520,    5497827098672,  281480009883648,\n",
       "         105588012876320,      17750335492,       2353006600,\n",
       "           1152125239552,       8590295043,       1610756608,\n",
       "         422221063397632,    1511828754496,  140739782639632,\n",
       "             70063785984,  211106232811538,      44023685248,\n",
       "         176196738385984,   18150603096128,   14851996909576,\n",
       "           1238024325440,    8933532828672,   35193037652224,\n",
       "             35450269697,  281474977239122,      17198809168,\n",
       "                25428241,       1476531200,   70387010371588,\n",
       "           4415259935904,    8804752163200,    4398080737312,\n",
       "         281629666844672,  141029580214272,   70506221010948,\n",
       "         211123412406530,   74767061221441,      69264770304,\n",
       "         140740172710154,   14293684977680,       2183136128,\n",
       "           1101877217280,    1100052695043,     550292726017,\n",
       "          70643623134752,  149817586098176,  105557448982560,\n",
       "          17594467749893,   72567834545160,    2203318496256,\n",
       "             44025528384,    8796101542288,    2268850176000,\n",
       "          70369566801920,         50628640,    8867765321728,\n",
       "          18318035517456,     572312780801,  175922430939136,\n",
       "            137438986642,   17593863771136,  281612428247808,\n",
       "         281492207206400,  281751196797056,   17872432660576,\n",
       "          35186587206145,   36979676807168,  844701018095616,\n",
       "        1198471973441536,     549856477281,  281518077378561,\n",
       "           2497523483136,        554696717, 1134696276688961,\n",
       "        1125985873330432,  281476051763720,    8869107466818,\n",
       "             77319897156, 2256203229167618,    8813272925824,\n",
       "        1125899932271680,     158997676033,  567350418079744,\n",
       "         283674142588944,    8800391135249]))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import tempfile\n",
    "# model_dir = tempfile.mkdtemp()\n",
    "# keras_estimator = tf.keras.estimator.model_to_estimator(\n",
    "#     keras_model=model, model_dir=model_dir)\n",
    "xt,yt = x.astype(int), y.astype(int)\n",
    "xt,yt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12 samples\n",
      "Epoch 1/250\n",
      "12/12 [==============================] - 0s 15ms/sample - loss: -644253274644069038570864640.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 2/250\n",
      "12/12 [==============================] - 0s 111us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 3/250\n",
      "12/12 [==============================] - 0s 123us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 4/250\n",
      "12/12 [==============================] - 0s 94us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 5/250\n",
      "12/12 [==============================] - 0s 97us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 6/250\n",
      "12/12 [==============================] - 0s 258us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 7/250\n",
      "12/12 [==============================] - 0s 167us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 8/250\n",
      "12/12 [==============================] - 0s 121us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 9/250\n",
      "12/12 [==============================] - 0s 123us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 10/250\n",
      "12/12 [==============================] - 0s 108us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 11/250\n",
      "12/12 [==============================] - 0s 116us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 12/250\n",
      "12/12 [==============================] - 0s 114us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 13/250\n",
      "12/12 [==============================] - 0s 192us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 14/250\n",
      "12/12 [==============================] - 0s 144us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 15/250\n",
      "12/12 [==============================] - 0s 127us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 16/250\n",
      "12/12 [==============================] - 0s 223us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 17/250\n",
      "12/12 [==============================] - 0s 235us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 18/250\n",
      "12/12 [==============================] - 0s 149us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 19/250\n",
      "12/12 [==============================] - 0s 183us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 20/250\n",
      "12/12 [==============================] - 0s 144us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 21/250\n",
      "12/12 [==============================] - 0s 114us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 22/250\n",
      "12/12 [==============================] - 0s 106us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 23/250\n",
      "12/12 [==============================] - 0s 97us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 24/250\n",
      "12/12 [==============================] - 0s 103us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 25/250\n",
      "12/12 [==============================] - 0s 99us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 26/250\n",
      "12/12 [==============================] - 0s 106us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 27/250\n",
      "12/12 [==============================] - 0s 95us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 28/250\n",
      "12/12 [==============================] - 0s 94us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 29/250\n",
      "12/12 [==============================] - 0s 100us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 30/250\n",
      "12/12 [==============================] - 0s 99us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 31/250\n",
      "12/12 [==============================] - 0s 99us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 32/250\n",
      "12/12 [==============================] - 0s 100us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 33/250\n",
      "12/12 [==============================] - 0s 116us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 34/250\n",
      "12/12 [==============================] - 0s 119us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 35/250\n",
      "12/12 [==============================] - 0s 181us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 36/250\n",
      "12/12 [==============================] - 0s 174us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 37/250\n",
      "12/12 [==============================] - 0s 147us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 38/250\n",
      "12/12 [==============================] - 0s 119us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 39/250\n",
      "12/12 [==============================] - 0s 115us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 40/250\n",
      "12/12 [==============================] - 0s 150us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 41/250\n",
      "12/12 [==============================] - 0s 149us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 42/250\n",
      "12/12 [==============================] - 0s 138us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 43/250\n",
      "12/12 [==============================] - 0s 112us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 44/250\n",
      "12/12 [==============================] - 0s 105us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 45/250\n",
      "12/12 [==============================] - 0s 103us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 46/250\n",
      "12/12 [==============================] - 0s 88us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 47/250\n",
      "12/12 [==============================] - 0s 104us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 48/250\n",
      "12/12 [==============================] - 0s 101us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 49/250\n",
      "12/12 [==============================] - 0s 104us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 50/250\n",
      "12/12 [==============================] - 0s 112us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 51/250\n",
      "12/12 [==============================] - 0s 93us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 52/250\n",
      "12/12 [==============================] - 0s 99us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 53/250\n",
      "12/12 [==============================] - 0s 98us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 54/250\n",
      "12/12 [==============================] - 0s 99us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 55/250\n",
      "12/12 [==============================] - 0s 99us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 56/250\n",
      "12/12 [==============================] - 0s 107us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 57/250\n",
      "12/12 [==============================] - 0s 114us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 58/250\n",
      "12/12 [==============================] - 0s 116us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 59/250\n",
      "12/12 [==============================] - 0s 115us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 60/250\n",
      "12/12 [==============================] - 0s 126us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 61/250\n",
      "12/12 [==============================] - 0s 118us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 62/250\n",
      "12/12 [==============================] - 0s 119us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 63/250\n",
      "12/12 [==============================] - 0s 114us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 64/250\n",
      "12/12 [==============================] - 0s 110us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 65/250\n",
      "12/12 [==============================] - 0s 115us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 66/250\n",
      "12/12 [==============================] - 0s 194us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 67/250\n",
      "12/12 [==============================] - 0s 146us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 68/250\n",
      "12/12 [==============================] - 0s 116us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 69/250\n",
      "12/12 [==============================] - 0s 100us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 70/250\n",
      "12/12 [==============================] - 0s 97us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 71/250\n",
      "12/12 [==============================] - 0s 100us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 72/250\n",
      "12/12 [==============================] - 0s 117us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 73/250\n",
      "12/12 [==============================] - 0s 101us/sample - loss: nan - binary_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/250\n",
      "12/12 [==============================] - 0s 100us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 75/250\n",
      "12/12 [==============================] - 0s 96us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 76/250\n",
      "12/12 [==============================] - 0s 96us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 77/250\n",
      "12/12 [==============================] - 0s 100us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 78/250\n",
      "12/12 [==============================] - 0s 99us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 79/250\n",
      "12/12 [==============================] - 0s 98us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 80/250\n",
      "12/12 [==============================] - 0s 98us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 81/250\n",
      "12/12 [==============================] - 0s 107us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 82/250\n",
      "12/12 [==============================] - 0s 113us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 83/250\n",
      "12/12 [==============================] - 0s 135us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 84/250\n",
      "12/12 [==============================] - 0s 165us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 85/250\n",
      "12/12 [==============================] - 0s 149us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 86/250\n",
      "12/12 [==============================] - 0s 114us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 87/250\n",
      "12/12 [==============================] - 0s 121us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 88/250\n",
      "12/12 [==============================] - 0s 124us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 89/250\n",
      "12/12 [==============================] - 0s 135us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 90/250\n",
      "12/12 [==============================] - 0s 132us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 91/250\n",
      "12/12 [==============================] - 0s 174us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 92/250\n",
      "12/12 [==============================] - 0s 128us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 93/250\n",
      "12/12 [==============================] - 0s 98us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 94/250\n",
      "12/12 [==============================] - 0s 135us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 95/250\n",
      "12/12 [==============================] - 0s 113us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 96/250\n",
      "12/12 [==============================] - 0s 111us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 97/250\n",
      "12/12 [==============================] - 0s 115us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 98/250\n",
      "12/12 [==============================] - 0s 114us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 99/250\n",
      "12/12 [==============================] - 0s 111us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 100/250\n",
      "12/12 [==============================] - 0s 116us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 101/250\n",
      "12/12 [==============================] - 0s 86us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 102/250\n",
      "12/12 [==============================] - 0s 97us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 103/250\n",
      "12/12 [==============================] - 0s 101us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 104/250\n",
      "12/12 [==============================] - 0s 106us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 105/250\n",
      "12/12 [==============================] - 0s 116us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 106/250\n",
      "12/12 [==============================] - 0s 118us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 107/250\n",
      "12/12 [==============================] - 0s 108us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 108/250\n",
      "12/12 [==============================] - 0s 125us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 109/250\n",
      "12/12 [==============================] - 0s 127us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 110/250\n",
      "12/12 [==============================] - 0s 170us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 111/250\n",
      "12/12 [==============================] - 0s 119us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 112/250\n",
      "12/12 [==============================] - 0s 88us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 113/250\n",
      "12/12 [==============================] - 0s 98us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 114/250\n",
      "12/12 [==============================] - 0s 143us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 115/250\n",
      "12/12 [==============================] - 0s 110us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 116/250\n",
      "12/12 [==============================] - 0s 93us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 117/250\n",
      "12/12 [==============================] - 0s 88us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 118/250\n",
      "12/12 [==============================] - 0s 99us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 119/250\n",
      "12/12 [==============================] - 0s 169us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 120/250\n",
      "12/12 [==============================] - 0s 102us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 121/250\n",
      "12/12 [==============================] - 0s 97us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 122/250\n",
      "12/12 [==============================] - 0s 105us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 123/250\n",
      "12/12 [==============================] - 0s 100us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 124/250\n",
      "12/12 [==============================] - 0s 120us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 125/250\n",
      "12/12 [==============================] - 0s 90us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 126/250\n",
      "12/12 [==============================] - 0s 87us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 127/250\n",
      "12/12 [==============================] - 0s 93us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 128/250\n",
      "12/12 [==============================] - 0s 95us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 129/250\n",
      "12/12 [==============================] - 0s 95us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 130/250\n",
      "12/12 [==============================] - 0s 126us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 131/250\n",
      "12/12 [==============================] - 0s 159us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 132/250\n",
      "12/12 [==============================] - 0s 142us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 133/250\n",
      "12/12 [==============================] - 0s 146us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 134/250\n",
      "12/12 [==============================] - 0s 124us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 135/250\n",
      "12/12 [==============================] - 0s 122us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 136/250\n",
      "12/12 [==============================] - 0s 111us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 137/250\n",
      "12/12 [==============================] - 0s 137us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 138/250\n",
      "12/12 [==============================] - 0s 155us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 139/250\n",
      "12/12 [==============================] - 0s 143us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 140/250\n",
      "12/12 [==============================] - 0s 101us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 141/250\n",
      "12/12 [==============================] - 0s 124us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 142/250\n",
      "12/12 [==============================] - 0s 100us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 143/250\n",
      "12/12 [==============================] - 0s 94us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 144/250\n",
      "12/12 [==============================] - 0s 99us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 145/250\n",
      "12/12 [==============================] - 0s 104us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 146/250\n",
      "12/12 [==============================] - 0s 103us/sample - loss: nan - binary_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/250\n",
      "12/12 [==============================] - 0s 107us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 148/250\n",
      "12/12 [==============================] - 0s 91us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 149/250\n",
      "12/12 [==============================] - 0s 91us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 150/250\n",
      "12/12 [==============================] - 0s 88us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 151/250\n",
      "12/12 [==============================] - 0s 103us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 152/250\n",
      "12/12 [==============================] - 0s 100us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 153/250\n",
      "12/12 [==============================] - 0s 116us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 154/250\n",
      "12/12 [==============================] - 0s 126us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 155/250\n",
      "12/12 [==============================] - 0s 154us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 156/250\n",
      "12/12 [==============================] - 0s 128us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 157/250\n",
      "12/12 [==============================] - 0s 110us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 158/250\n",
      "12/12 [==============================] - 0s 126us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 159/250\n",
      "12/12 [==============================] - 0s 102us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 160/250\n",
      "12/12 [==============================] - 0s 111us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 161/250\n",
      "12/12 [==============================] - 0s 101us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 162/250\n",
      "12/12 [==============================] - 0s 128us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 163/250\n",
      "12/12 [==============================] - 0s 111us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 164/250\n",
      "12/12 [==============================] - 0s 124us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 165/250\n",
      "12/12 [==============================] - 0s 141us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 166/250\n",
      "12/12 [==============================] - 0s 150us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 167/250\n",
      "12/12 [==============================] - 0s 115us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 168/250\n",
      "12/12 [==============================] - 0s 109us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 169/250\n",
      "12/12 [==============================] - 0s 141us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 170/250\n",
      "12/12 [==============================] - 0s 92us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 171/250\n",
      "12/12 [==============================] - 0s 99us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 172/250\n",
      "12/12 [==============================] - 0s 119us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 173/250\n",
      "12/12 [==============================] - 0s 95us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 174/250\n",
      "12/12 [==============================] - 0s 106us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 175/250\n",
      "12/12 [==============================] - 0s 108us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 176/250\n",
      "12/12 [==============================] - 0s 88us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 177/250\n",
      "12/12 [==============================] - 0s 124us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 178/250\n",
      "12/12 [==============================] - 0s 105us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 179/250\n",
      "12/12 [==============================] - 0s 170us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 180/250\n",
      "12/12 [==============================] - 0s 124us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 181/250\n",
      "12/12 [==============================] - 0s 164us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 182/250\n",
      "12/12 [==============================] - 0s 147us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 183/250\n",
      "12/12 [==============================] - 0s 141us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 184/250\n",
      "12/12 [==============================] - 0s 133us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 185/250\n",
      "12/12 [==============================] - 0s 133us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 186/250\n",
      "12/12 [==============================] - 0s 149us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 187/250\n",
      "12/12 [==============================] - 0s 96us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 188/250\n",
      "12/12 [==============================] - 0s 95us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 189/250\n",
      "12/12 [==============================] - 0s 85us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 190/250\n",
      "12/12 [==============================] - 0s 97us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 191/250\n",
      "12/12 [==============================] - 0s 108us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 192/250\n",
      "12/12 [==============================] - 0s 87us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 193/250\n",
      "12/12 [==============================] - 0s 87us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 194/250\n",
      "12/12 [==============================] - 0s 105us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 195/250\n",
      "12/12 [==============================] - 0s 102us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 196/250\n",
      "12/12 [==============================] - 0s 98us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 197/250\n",
      "12/12 [==============================] - 0s 97us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 198/250\n",
      "12/12 [==============================] - 0s 105us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 199/250\n",
      "12/12 [==============================] - 0s 115us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 200/250\n",
      "12/12 [==============================] - 0s 118us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 201/250\n",
      "12/12 [==============================] - 0s 121us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 202/250\n",
      "12/12 [==============================] - 0s 160us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 203/250\n",
      "12/12 [==============================] - 0s 127us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 204/250\n",
      "12/12 [==============================] - 0s 120us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 205/250\n",
      "12/12 [==============================] - 0s 101us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 206/250\n",
      "12/12 [==============================] - 0s 164us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 207/250\n",
      "12/12 [==============================] - 0s 112us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 208/250\n",
      "12/12 [==============================] - 0s 121us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 209/250\n",
      "12/12 [==============================] - 0s 119us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 210/250\n",
      "12/12 [==============================] - 0s 149us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 211/250\n",
      "12/12 [==============================] - 0s 151us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 212/250\n",
      "12/12 [==============================] - 0s 154us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 213/250\n",
      "12/12 [==============================] - 0s 124us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 214/250\n",
      "12/12 [==============================] - 0s 120us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 215/250\n",
      "12/12 [==============================] - 0s 134us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 216/250\n",
      "12/12 [==============================] - 0s 89us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 217/250\n",
      "12/12 [==============================] - 0s 104us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 218/250\n",
      "12/12 [==============================] - 0s 128us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 219/250\n",
      "12/12 [==============================] - 0s 91us/sample - loss: nan - binary_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/250\n",
      "12/12 [==============================] - 0s 108us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 221/250\n",
      "12/12 [==============================] - 0s 89us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 222/250\n",
      "12/12 [==============================] - 0s 104us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 223/250\n",
      "12/12 [==============================] - 0s 110us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 224/250\n",
      "12/12 [==============================] - 0s 114us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 225/250\n",
      "12/12 [==============================] - 0s 149us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 226/250\n",
      "12/12 [==============================] - 0s 143us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 227/250\n",
      "12/12 [==============================] - 0s 124us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 228/250\n",
      "12/12 [==============================] - 0s 109us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 229/250\n",
      "12/12 [==============================] - 0s 118us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 230/250\n",
      "12/12 [==============================] - 0s 119us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 231/250\n",
      "12/12 [==============================] - 0s 147us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 232/250\n",
      "12/12 [==============================] - 0s 126us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 233/250\n",
      "12/12 [==============================] - 0s 167us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 234/250\n",
      "12/12 [==============================] - 0s 201us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 235/250\n",
      "12/12 [==============================] - 0s 115us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 236/250\n",
      "12/12 [==============================] - 0s 119us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 237/250\n",
      "12/12 [==============================] - 0s 119us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 238/250\n",
      "12/12 [==============================] - 0s 125us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 239/250\n",
      "12/12 [==============================] - 0s 125us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 240/250\n",
      "12/12 [==============================] - 0s 126us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 241/250\n",
      "12/12 [==============================] - 0s 124us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 242/250\n",
      "12/12 [==============================] - 0s 122us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 243/250\n",
      "12/12 [==============================] - 0s 125us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 244/250\n",
      "12/12 [==============================] - 0s 127us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 245/250\n",
      "12/12 [==============================] - 0s 128us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 246/250\n",
      "12/12 [==============================] - 0s 143us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 247/250\n",
      "12/12 [==============================] - 0s 193us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 248/250\n",
      "12/12 [==============================] - 0s 144us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 249/250\n",
      "12/12 [==============================] - 0s 149us/sample - loss: nan - binary_accuracy: 0.0000e+00\n",
      "Epoch 250/250\n",
      "12/12 [==============================] - 0s 102us/sample - loss: nan - binary_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb71a0b4898>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xt[:12],yt[:12],epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = test_x[-1:]\n",
    "#val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "predictions = model.predict(l)\n",
    "\n",
    "yo, accuracy = model.evaluate(test_x, test_y)\n",
    "print('Accuracy: %.2f' % (accuracy*1000000000000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_51_input to have shape (24,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-c0b16ab11396>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/drawkaos/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/drawkaos/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/drawkaos/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    427\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/drawkaos/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[0;32m--> 646\u001b[0;31m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[1;32m    647\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/drawkaos/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2383\u001b[0;31m         batch_size=batch_size)\n\u001b[0m\u001b[1;32m   2384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[0;32m~/.virtualenvs/drawkaos/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[0;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2410\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2412\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/drawkaos/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    580\u001b[0m                              \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m                              str(data_shape))\n\u001b[0m\u001b[1;32m    583\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_51_input to have shape (24,) but got array with shape (1,)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ({drawNumber: (None,), ball1: (None,), ball2: (None,), ball3: (None,), ball4: (None,), ball5: (None,), ball6: (None,), bonusBall: (None,)}, (None, 6)), types: ({drawNumber: tf.int32, ball1: tf.int32, ball2: tf.int32, ball3: tf.int32, ball4: tf.int32, ball5: tf.int32, ball6: tf.int32, bonusBall: tf.int32}, tf.int32)>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan]], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
